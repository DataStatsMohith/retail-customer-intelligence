{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 \u2014 ML-Based Customer Segmentation\n\n> Moving beyond manual RFM scoring to **unsupervised machine learning** \u2014 letting the data find its own natural groupings.\n\nAlgorithms covered:\n- **KMeans** \u2014 most interpretable, industry standard\n- **DBSCAN** \u2014 density-based, finds outliers automatically\n- **Elbow method + Silhouette analysis** \u2014 how to choose the right number of clusters\n- **PCA visualisation** \u2014 showing high-dimensional clusters in 2D",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score\nfrom sklearn.decomposition import PCA\nimport sys; sys.path.insert(0, '.')\nfrom src.data.loader import load_transactions\nfrom src.data.preprocessor import clean_transactions, add_time_features, get_snapshot_date\nfrom src.features.rfm_features import compute_rfm, score_rfm, add_behavioural_features\nfrom src.models.segmentation import CustomerSegmentation\nimport warnings; warnings.filterwarnings('ignore')\n\nplt.rcParams.update({'figure.dpi': 120, 'axes.spines.top': False, 'axes.spines.right': False})\n\ntransactions = load_transactions()\ntransactions = clean_transactions(transactions)\ntransactions = add_time_features(transactions)\nsnapshot = get_snapshot_date(transactions)\nrfm = compute_rfm(transactions, snapshot)\nrfm = score_rfm(rfm)\nrfm = add_behavioural_features(transactions, rfm)\n\nprint(f\"Features available: {rfm.columns.tolist()}\")\nprint(f\"Customers: {len(rfm):,}\")\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Finding the Optimal Number of Clusters\n\nTwo complementary methods:\n1. **Elbow method** \u2014 where does inertia stop dropping sharply?\n2. **Silhouette score** \u2014 how well-separated are the clusters? (higher = better, max 1.0)",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "seg_model = CustomerSegmentation(n_clusters=5)\nresults = seg_model.find_optimal_k(rfm, k_range=range(2, 11))\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Elbow\naxes[0].plot(results['k'], results['inertia'], 'bo-', linewidth=2, markersize=8)\naxes[0].set_title('Elbow Method \u2014 Inertia vs K', fontweight='bold', fontsize=13)\naxes[0].set_xlabel('Number of Clusters (K)')\naxes[0].set_ylabel('Inertia (within-cluster sum of squares)')\naxes[0].axvline(5, color='red', linestyle='--', alpha=0.7, label='Selected K=5')\naxes[0].legend()\n\n# Silhouette\naxes[1].plot(results['k'], results['silhouette'], 'rs-', linewidth=2, markersize=8)\naxes[1].set_title('Silhouette Score vs K', fontweight='bold', fontsize=13)\naxes[1].set_xlabel('Number of Clusters (K)')\naxes[1].set_ylabel('Silhouette Score (higher = better)')\nbest_k = results['k'][np.argmax(results['silhouette'])]\naxes[1].axvline(best_k, color='blue', linestyle='--', alpha=0.7, label=f'Best K={best_k}')\naxes[1].legend()\n\nplt.tight_layout()\nplt.savefig('reports/figures/03_optimal_k.png', bbox_inches='tight')\nplt.show()\nprint(f\"Best K by silhouette: {best_k}\")\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## KMeans Clustering",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "seg_model = CustomerSegmentation(n_clusters=5, random_state=42)\nrfm_seg, metrics = seg_model.fit_kmeans(rfm)\nrfm_seg = seg_model.label_segments(rfm_seg)\n\nprint(\"=== KMeans Results ===\")\nprint(f\"Silhouette Score  : {metrics['silhouette']:.4f}  (>0.25 = reasonable, >0.5 = strong)\")\nprint(f\"Davies-Bouldin    : {metrics['davies_bouldin']:.4f}  (lower = better)\")\nprint(f\"\\nSegment distribution:\")\nprint(rfm_seg['segment_label'].value_counts().to_string())\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# PCA visualisation\nfeature_cols = [c for c in ['recency','frequency','monetary_log','avg_basket_size','unique_products','weekend_ratio'] if c in rfm_seg.columns]\nX = rfm_seg[feature_cols].fillna(0).values\nX_scaled = StandardScaler().fit_transform(X)\npca = PCA(n_components=2, random_state=42)\ncomponents = pca.fit_transform(X_scaled)\n\nsegment_labels = rfm_seg['segment_label'].unique()\ncolors = {'Champions':'#2ecc71','Loyal Customers':'#3498db',\n          'Potential Loyalists':'#f39c12','At Risk':'#e74c3c','Lost / Hibernating':'#95a5a6'}\n\nfig, ax = plt.subplots(figsize=(12, 8))\nfor label in segment_labels:\n    mask = rfm_seg['segment_label'] == label\n    ax.scatter(components[mask, 0], components[mask, 1],\n               c=colors.get(label, 'grey'), label=label, alpha=0.6, s=25)\n\nax.set_title(f'Customer Segments \u2014 PCA Projection\\n(Explained variance: {sum(pca.explained_variance_ratio_)*100:.1f}%)',\n             fontsize=14, fontweight='bold')\nax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\nax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\nax.legend(loc='upper right', framealpha=0.9)\nplt.tight_layout()\nplt.savefig('reports/figures/03_pca_clusters.png', bbox_inches='tight')\nplt.show()\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cluster Profiles \u2014 What Makes Each Segment Unique?",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "profile = rfm_seg.groupby('segment_label')[['recency','frequency','monetary','avg_basket_size','unique_products']].mean().round(1)\nprint(\"=== Cluster Profiles ===\")\nprint(profile.to_string())\n\n# Radar/spider not needed \u2014 simple heatmap is cleaner for presentations\nprofile_norm = (profile - profile.min()) / (profile.max() - profile.min())\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(profile_norm.T, annot=profile.T, fmt='.0f', cmap='RdYlGn',\n            linewidths=0.5, ax=ax, cbar_kws={'label': 'Normalised Score'})\nax.set_title('Segment Feature Profiles\\n(cell values = raw averages)', fontweight='bold', fontsize=13)\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')\nplt.tight_layout()\nplt.savefig('reports/figures/03_cluster_profiles.png', bbox_inches='tight')\nplt.show()\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## DBSCAN \u2014 Density-Based Clustering\n\nDifference from KMeans: DBSCAN doesn't require specifying K upfront and identifies noise/outlier customers automatically.",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "seg_dbscan = CustomerSegmentation()\nrfm_db, db_metrics = seg_dbscan.fit_dbscan(rfm, eps=1.2, min_samples=10)\nprint(f\"DBSCAN found {db_metrics['n_clusters']} clusters\")\nprint(f\"Noise/outlier customers: {db_metrics['n_noise']} ({db_metrics['n_noise']/len(rfm)*100:.1f}%)\")\nprint(\"\\nThese 'noise' customers are highly unusual buyers \u2014 worth investigating separately for VIP or fraud detection.\")\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Model Comparison\n\n| Method | Silhouette | Interpretability | Scalability | Best For |\n|--------|------------|-----------------|-------------|----------|\n| **KMeans** | 0.381 | High | High | Production segmentation |\n| **DBSCAN** | N/A | Medium | Medium | Outlier detection |\n| **RFM Scoring** | N/A | Very High | High | Quick business reporting |\n\n**Decision: KMeans chosen for production** \u2014 best balance of performance and interpretability.\n\n**Next:** \u2192 `04_Recommendation_Engine.ipynb`",
   "id": "md"
  }
 ]
}