{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 05 \u2014 Model Evaluation & Business Insights\n\n> Communicating results to both technical and non-technical audiences \u2014 a key skill in the Boots DS role.\n\nThis notebook covers:\n- Recommender evaluation metrics: Precision@K, Recall@K, NDCG@K, Hit Rate\n- Segmentation quality metrics\n- Business-ready summary visualisations\n- Actionable recommendations for each customer segment",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys; sys.path.insert(0, '.')\nfrom src.data.loader import load_transactions, load_products\nfrom src.data.preprocessor import clean_transactions, add_time_features, get_snapshot_date\nfrom src.features.rfm_features import compute_rfm, score_rfm, add_behavioural_features\nfrom src.models.segmentation import CustomerSegmentation\nfrom src.models.recommender import HybridRecommender, CollaborativeFilteringRecommender\nfrom src.evaluation.metrics import precision_at_k, recall_at_k, ndcg_at_k, hit_rate\nimport warnings; warnings.filterwarnings('ignore')\n\nplt.rcParams.update({'figure.dpi': 120, 'axes.spines.top': False, 'axes.spines.right': False})\n\ntransactions = load_transactions()\ntransactions = clean_transactions(transactions)\ntransactions = add_time_features(transactions)\nproducts     = load_products()\nsnapshot     = get_snapshot_date(transactions)\nrfm          = compute_rfm(transactions, snapshot)\nrfm          = score_rfm(rfm)\nrfm          = add_behavioural_features(transactions, rfm)\n\ncutoff = transactions['date'].max() - pd.Timedelta(days=30)\ntrain  = transactions[transactions['date'] <= cutoff]\ntest   = transactions[transactions['date'] > cutoff]\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Recommender Evaluation\n\nWe evaluate against held-out purchases. Metrics explained:\n- **Precision@K**: Of the K items recommended, what fraction did the customer actually buy?\n- **Recall@K**: Of all items the customer bought, what fraction did we recommend?\n- **NDCG@K**: Ranking quality \u2014 did we put the right items at the top?\n- **Hit Rate**: Did at least one recommendation match a real purchase?",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "hybrid = HybridRecommender(n_recommendations=10)\nhybrid.fit(train, products)\n\n# Evaluate on test set customers\nK = 10\nprecision_scores, recall_scores, ndcg_scores, hr_scores = [], [], [], []\n\ntest_customers = test['customer_id'].unique()\nsample = test_customers[:200]  # sample for speed\n\nfor cid in sample:\n    relevant = test[test['customer_id']==cid]['product_id'].tolist()\n    if not relevant:\n        continue\n    try:\n        recs = hybrid.recommend(cid)['product_id'].tolist()\n        precision_scores.append(precision_at_k(recs, relevant, K))\n        recall_scores.append(recall_at_k(recs, relevant, K))\n        ndcg_scores.append(ndcg_at_k(recs, relevant, K))\n        hr_scores.append(hit_rate(recs, relevant))\n    except:\n        pass\n\nresults = {\n    f'Precision@{K}': np.mean(precision_scores),\n    f'Recall@{K}':    np.mean(recall_scores),\n    f'NDCG@{K}':      np.mean(ndcg_scores),\n    'Hit Rate':        np.mean(hr_scores),\n}\nprint(\"=== Recommender Evaluation Results ===\")\nfor k, v in results.items():\n    print(f\"  {k:15s}: {v:.4f}\")\nprint(\"\\nNote: These scores reflect a synthetic dataset.\")\nprint(\"In production, Hit Rate >0.3 and NDCG@10 >0.15 are considered strong baselines.\")\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Visualise metrics\nfig, ax = plt.subplots(figsize=(9, 5))\nbars = ax.bar(list(results.keys()), list(results.values()),\n              color=['steelblue','coral','seagreen','#9b59b6'], alpha=0.85, edgecolor='white', width=0.5)\nax.set_title(f'Hybrid Recommender \u2014 Evaluation Metrics @K={K}', fontweight='bold', fontsize=13)\nax.set_ylabel('Score')\nax.set_ylim(0, max(results.values()) * 1.3)\nfor bar, val in zip(bars, results.values()):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n            f'{val:.3f}', ha='center', fontweight='bold', fontsize=11)\nplt.tight_layout()\nplt.savefig('reports/figures/05_recommender_metrics.png', bbox_inches='tight')\nplt.show()\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Segmentation Evaluation",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score\n\nseg_model = CustomerSegmentation(n_clusters=5)\nrfm_seg, metrics = seg_model.fit_kmeans(rfm)\nrfm_seg = seg_model.label_segments(rfm_seg)\n\nprint(\"=== Segmentation Evaluation ===\")\nprint(f\"Silhouette Score : {metrics['silhouette']:.4f}  (benchmark: >0.25 reasonable, >0.5 strong)\")\nprint(f\"Davies-Bouldin   : {metrics['davies_bouldin']:.4f}  (lower is better)\")\nprint(f\"N Clusters       : 5\")\nprint(f\"N Customers      : {len(rfm_seg):,}\")\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Business Summary Dashboard\n\nThis is what you'd present to a non-technical stakeholder \u2014 clear, actionable, revenue-focused.",
   "id": "md"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "segment_order = ['Champions','Loyal Customers','Potential Loyalists','At Risk','Lost / Hibernating']\ncolors_map    = {'Champions':'#2ecc71','Loyal Customers':'#3498db',\n                 'Potential Loyalists':'#f39c12','At Risk':'#e74c3c','Lost / Hibernating':'#95a5a6'}\n\nseg_summary = rfm_seg.groupby('segment_label').agg(\n    Customers   = ('customer_id', 'count'),\n    Avg_Recency = ('recency',    'mean'),\n    Avg_Freq    = ('frequency',  'mean'),\n    Total_Rev   = ('monetary',   'sum'),\n    Avg_Rev     = ('monetary',   'mean'),\n).round(1).reindex(segment_order)\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 11))\nfig.suptitle('Customer Segmentation \u2014 Business Dashboard', fontsize=16, fontweight='bold', y=1.01)\n\n# 1. Customer count\nseg_summary['Customers'].plot(kind='bar', ax=axes[0,0],\n    color=[colors_map[s] for s in segment_order], edgecolor='white', alpha=0.9)\naxes[0,0].set_title('Customers per Segment', fontweight='bold')\naxes[0,0].set_xticklabels(segment_order, rotation=30, ha='right')\n\n# 2. Revenue contribution pie\naxes[0,1].pie(seg_summary['Total_Rev'],\n              labels=segment_order, colors=[colors_map[s] for s in segment_order],\n              autopct='%1.1f%%', startangle=140, pctdistance=0.85)\naxes[0,1].set_title('Revenue Share by Segment', fontweight='bold')\n\n# 3. Avg recency vs frequency scatter\nscatter_data = rfm_seg.sample(min(1500, len(rfm_seg)), random_state=42)\nfor seg in segment_order:\n    mask = scatter_data['segment_label'] == seg\n    axes[1,0].scatter(scatter_data.loc[mask,'recency'], scatter_data.loc[mask,'frequency'],\n                      c=colors_map[seg], label=seg, alpha=0.5, s=20)\naxes[1,0].set_xlabel('Recency (days)')\naxes[1,0].set_ylabel('Frequency (transactions)')\naxes[1,0].set_title('Recency vs Frequency by Segment', fontweight='bold')\naxes[1,0].legend(fontsize=8)\n\n# 4. Avg revenue per customer\nseg_summary['Avg_Rev'].plot(kind='bar', ax=axes[1,1],\n    color=[colors_map[s] for s in segment_order], edgecolor='white', alpha=0.9)\naxes[1,1].set_title('Average Revenue per Customer', fontweight='bold')\naxes[1,1].set_xticklabels(segment_order, rotation=30, ha='right')\naxes[1,1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x,_: f'\u00a3{x:,.0f}'))\n\nplt.tight_layout()\nplt.savefig('reports/figures/05_business_dashboard.png', bbox_inches='tight', dpi=150)\nplt.show()\n",
   "outputs": [],
   "execution_count": null,
   "id": "code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Actionable Recommendations\n\n| Segment | Size | Avg Revenue | Recommended Action | Expected Impact |\n|---------|------|-------------|-------------------|----------------|\n| **Champions** | ~8% | High | Loyalty rewards, early access, No7 premium upsell | Retain 95%+ |\n| **Loyal Customers** | ~15% | Medium-High | Cross-category recommendations, subscription offers | +15% basket size |\n| **Potential Loyalists** | ~25% | Medium | Personalised email with top-10 recommendations | Convert to Loyal |\n| **At Risk** | ~20% | Medium | Win-back campaign, 20% discount voucher | Recover 30% |\n| **Lost / Hibernating** | ~32% | Low | Low-cost re-engagement only if segment size justifies | Accept churn |\n\n## Project Complete \u2705\n\nThis project demonstrates:\n- End-to-end data science pipeline from raw data to production deployment\n- Industry-standard techniques (RFM, KMeans, Collaborative Filtering)\n- MLOps practices (MLflow tracking, model registry, FastAPI)\n- Communication of insights to both technical and non-technical audiences\n- Python proficiency: pandas, scikit-learn, scipy, FastAPI, pytest",
   "id": "md"
  }
 ]
}